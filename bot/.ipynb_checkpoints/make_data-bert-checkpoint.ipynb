{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple chat-bot example BERT - torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import annoy\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_otvety = r'D:\\train\\Otvety/Otvety.txt'\n",
    "patch_prepared_answers = r'D:\\train\\Otvety/prepared_answers.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lqw\\AppData\\Local\\Temp/ipykernel_15868/2597431552.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for line in tqdm_notebook(fin):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd33d60efac4fce90ecccf422ad21d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = ''\n",
    "with open(patch_prepared_answers, \"w\",encoding = 'utf-8') as fout:\n",
    "    with open(patch_otvety, \"r\",encoding = 'utf-8') as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                if data !=\"\":\n",
    "                    fout.write(data.strip()+'\\n')\n",
    "                data = ''\n",
    "                continue\n",
    "            my_line = line.replace(\"\\t\", \" \")\n",
    "            my_line = my_line.replace(\"\\n\", \" \").strip()\n",
    "            data += my_line + \"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_answers(text):\n",
    "    text = re.sub(r'\\n',' ',text)\n",
    "    text = re.sub(r'<br>',' ',text)\n",
    "    text = re.sub(r'</p>',' ',text)\n",
    "    text = re.sub(r'<ul>',' ',text)\n",
    "    text = re.sub(r'<li>',' ',text)\n",
    "    text = re.sub(r'<p>',' ',text)\n",
    "    text = re.sub(r'[\\n<br></p><ul><li><p>]',' ',text)\n",
    "    text = re.sub(r'<.{0,4}>',' ',text)\n",
    "    text = re.sub(r' +',' ',text)\n",
    "    text = re.sub(r' \\.','.',text)\n",
    "    text = re.sub(r' \\!','!',text)\n",
    "    text = re.sub(r' \\?','?',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_questions(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w+]',' ',text)\n",
    "    text = re.sub(r' +',' ',text)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "questions = []\n",
    "answers = []\n",
    "with open(patch_prepared_answers, 'r',encoding = 'utf-8') as f:\n",
    "    for line in f:\n",
    "        line = line.split(\"\\t\")\n",
    "        questions.append(clean_text_questions(line[0]))\n",
    "        answers.append([clean_text_answers (i) for i in line[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['вопрос о тдв давно и хорошо отдыхаем лично вам здесь кого советовали завести ',\n",
       "       'как парни относятся к цветным линзам если у девушки то зеленые глаза то голубые ',\n",
       "       'что делать сегодня нашёл 2 миллиона рублей ', ...,\n",
       "       ' если это мое то оно никуда от меня не денется ',\n",
       "       'а вы халяву любите или совесть имеете ',\n",
       "       'так много разных гороскопов кто нибудь может посоветоваь хороший сайт с правдивой информацией о совместимости знаков зодиака или может быть есть советы из личного опыта я лев а он скорпиончик '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['хомячка....', 'мужика, йопаря, собачку и 50 кошек))).', 'Общение!).', 'паучка.', 'Да пол мне бы памыть! А таг то ни чо. Типа ни каво!.', 'я тут вообще что бы пообщаться.....', 'А мне советовали сиси завести...))).', 'Ну, слава богу, мужика завести ещё не советовали))) А вот сватать к кому только не сватали).', 'мне тут советовали завести любовника, мужа и много кошек ))) приветик ))). ']),\n",
       "       list(['меня вобще прикалывает эта тема :).', 'когда этобыло редкость - было забавно, а когда все знают, что эта фальшивка, то уже не прикольно, как силиконовые сиськи или как налепленные синтетические волосы. ']),\n",
       "       list(['Если это \"счастье \" действительно на вас свалилось, лучше пойти в милицию и заявить о находке. Такие деньги просто так не терют, а что самое интересное их неприменно будут искать и поверьте мне найдут, видел подобное в жизни. Можно нарваться на бабушку конечно, которая хотела помоч внуку с покупкой квартиры, а можно на бандитов, которые будут с вами разговаривать иначе чем бабушка с милицией. Выбор за вами, есть еще конечно шанс, что это подарок с выше за котрый с вас никто не спросит, тогда лучше отдать хотябы 500 на благотворительность. дабы не спугнуть удачу!.', 'Что не знаешь что делать? тогда отдай тому кто знает, а если серьезно- можешь отнести их в полицию они найдут что с ними сделать, или другой вариант возьми чуть, а остальные надежно спрячь пускай лежат будешь брать сколько необходимо чтобы подозрений не вызывало не у кого от куда у тебя такие деньги..', 'А не скажете местечко, где такие находки попадаются?))) Если бы я нашла два миллиона, я прежде всего растерялась и пребывала в шоке. В первую очередь думаю, нужно убедиться что они настоящие. В полицию я бы скорее всего не пошла, деньги были бы очень кстати..', 'Я думаю следует отметить это дело как следует, ну а если хотите поделиться с полицией, то смело отправляйтесь в ближайшее отделение..', 'первым делом - нужно поспать ))) И дурацких ошибок не совершите, и мудрый совет от бессознательного получите во время сна ).', 'Одолжите миллион мне, нам на покупку квартиры не хватает))Так будет сохраннее..', 'Если не знаешь, как развести толпу, то лучше помолчи. Ну а если и вправду нашёл такую сумму, то распространяться, тем более в интернете, об этом не следует.. ']),\n",
       "       ...,\n",
       "       list(['Если плохо обращаться со СВОЕЙ собакой, она сдохнет.. Это как аллегория Да, НАШЕ-НАМ дается, но сохраним мы его или нет - наш выбор На эту тему есть замечательная притча: В семье простого рыбака родился сын и Ангелы предрекли ему стать очень богатым человеком. Мальчик вырос, отцовскому ремеслу не учился- зачем? Ведь он и так станет богатым. Шло время, он лежал на печи и ждал обещанного богатства. Вот как то в лес пошел и в яму там провалился, хотел за жизнь бороться, да не стал. Думает, все равно я не умру, я еще богатым не стал. Помер он от голода в этой яме. И на небесах Ангелам претензию предьявляет \" А как же обещанное вами богатство? \" А Ангелы только удивляются: Да как пришло время, стали мы тебы искать среди рыбаков - а нет нигде тебя. Стали среди других ремесел искать - нет! Пока нашли, время прошло.. Когда ты в яму упал, мы тебе клад подложили, думали копать начнешь.. *****.', 'первый.', 'выбери к чему душа лежит.', 'если это твой то скоро станет моим.', 'Главное здесь -поменять этот знак----\"?\"-----на этот ------\"!\"------И уверенность заменит сомнение!!!.', 'Не зевай, пилот! Враг может спиздить самолет)!.', 'Один из законов Мёрфи гласит: \"Лучшие варианты - первый и последний. \")) А это тоже из его законов)) : \"Если появилось много хороших вариантов - значит, скоро не останется ни одного. \" \"То, что ищешь, найдешь только обыскав все. \" \"Начинать поиски надо с самого неподходящего места. \" \"Если вам все равно, где вы находитесь, значит вы не заблудились. \" \"Не ошибается тот, кто ничего не делает. \" htt : ogs.ma. ma ma anhen 227FFBAC3B1D089A.htm.', 'Как в анекдоте про чудика, который разгуливал по перрону уверенный в том, что поезд без него не уйдет, т. к. билет - у него в кармане.).', 'расслабляться не нужно.... ']),\n",
       "       list(['Люблю, но нет её..', 'не то, чо люблю Но игры из инета качаю пиратские.', 'Люблю и имею умеренно..', 'халяву люблю, совесть имею.... несколько раз в день....', 'халява- так на чукотке называют проститутку. причем тут совесть?.', 'От халявы не разбогатеешь Лучше совесть иметь.', 'Наличие совести не исключает любовь к халяве....', 'Люблю больше дарить чем получать подарки, некоторые не верят, но это так.', 'Нет, я испытываю удовлетворение от того, что достигаю сама....', 'Не люблю..', 'Совесть на холяву не получишь.. ']),\n",
       "       list(['[ссылка заблокирована по решению администрации проекта]. '])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_answers = r'D:\\train\\Otvety\\bert/answers.npy'\n",
    "path_questions = r'D:\\train\\Otvety\\bert/questions.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = np.array(answers,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.array(questions,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_answers,answers)\n",
    "np.save(path_questions,questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = np.load(path_answers,allow_pickle=True,encoding='bytes')\n",
    "questions = np.load(path_questions,allow_pickle=True,encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_len =np.array( [len(i) for i in questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.0, 124.61392360454522, 127.0, 194.0, 385.0, 5387)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(q_len), np.mean(q_len), np.quantile(q_len, 0.75), np.quantile(q_len, 0.85), np.quantile(q_len, 0.95), np.max(q_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3702ba8f3c44be899a1e0cbbd15fc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1163420.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 16h 55min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bert_index = annoy.AnnoyIndex(768 , 'angular')\n",
    "counter = 0\n",
    "\n",
    "for question in tqdm_notebook(questions):\n",
    "    question = question[:400]\n",
    "    tok = tokenizer(question, return_token_type_ids=False, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        out_state = model(**tok)[1].numpy()[0]\n",
    "    bert_index.add_item(counter, out_state)\n",
    "    counter += 1\n",
    "        \n",
    "\n",
    "bert_index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_index = r'D:\\train\\Otvety\\bert/index_full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_index.save(patch_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_index = annoy.AnnoyIndex(768 , 'angular')\n",
    "bert_index.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_respons(question):\n",
    "    question = clean_text_questions(question)\n",
    "    question = question[:400]\n",
    "    tok = tokenizer(question, return_token_type_ids=False, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        vector = model(**tok)[1].numpy()[0]\n",
    "    answer_ind = bert_index.get_nns_by_vector(vector, 1)\n",
    "    my_answers = answers[answer_ind][0]\n",
    "    return str(np.random.choice(my_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Сколько раз нужно отжиматься?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "семь или один.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(get_respons(TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 365, в високосный год 366 дней. \n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Сколько дней в году\"\n",
    "\n",
    "print(get_respons(TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 января начало Новолуния в 1:40. Потом растущая..\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Сколько до луны?\"\n",
    "\n",
    "print(get_respons(TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y menya v4e a ,te ya eto tak adyet????.\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Сегодня будет секс?\"\n",
    "\n",
    "print(get_respons(TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в сайте знакомств.\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"Как найти жену?\"\n",
    "\n",
    "print(get_respons(TEXT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
